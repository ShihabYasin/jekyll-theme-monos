---
layout: post 
title: Generative Adversarial Networks - GAN  
date: 2020-05-05 16:20:23 +0900 
category: ML 
tag: ML 
---

## 1. Generative Adversarial Networks(GAN) Features: 
 
1. Generative Adversarial Networks, or GANs, are a deep-learning-based generative model.
2. The GAN model architecture involves two sub-models: a generator model for generating new examples and a discriminator model for classifying whether generated examples are real, from the domain, or fake, generated by the generator model.

 - Generator. Model that is used to generate new plausible examples from the problem domain.
 - Discriminator. Model that is used to classify examples as real (from the domain) or fake (generated).

## _Architecture:_

## The Generator Model:

The generator model takes a fixed-length random vector as input and generates a sample in the domain.

The vector is drawn from randomly from a Gaussian distribution, and the vector is used to seed the generative process. After training, points in this multidimensional vector space will correspond to points in the problem domain, forming a compressed representation of the data distribution.

This vector space is referred to as a latent space, or a vector space comprised of latent variables. Latent variables, or hidden variables, are those variables that are important for a domain but are not directly observable.


<p align="center">
<img src="https://github.com/ShihabYasin/shihabyasin.github.io/blob/gh-pages/public/img/27.png?raw=true?" alt="Illustration" width="150px" height="180px"/>
</p>


## The Discriminator Model:

The discriminator model takes an example from the domain as input (real or generated) and predicts a binary class label of real or fake (generated).

The real example comes from the training dataset. The generated examples are output by the generator model.

The discriminator is a normal (and well understood) classification model.

After the training process, the discriminator model is discarded as we are interested in the generator.

Sometimes, the generator can be repurposed as it has learned to effectively extract features from examples in the problem domain. Some or all of the feature extraction layers can be used in transfer learning applications using the same or similar input data.



<p align="center">
<img src="https://github.com/ShihabYasin/shihabyasin.github.io/blob/gh-pages/public/img/28.png?raw=true?" alt="Illustration" width="150px" height="180"/>
</p>


## Zero Sum Game (GAN):
Generative modeling is an unsupervised learning problem, as we discussed in the previous section, although a clever property of the GAN architecture is that the training of the generative model is framed as a supervised learning problem.

The two models, the generator and discriminator, are trained together. The generator generates a batch of samples, and these, along with real examples from the domain, are provided to the discriminator and classified as real or fake.

The discriminator is then updated to get better at discriminating real and fake samples in the next round, and importantly, the generator is updated based on how well, or not, the generated samples fooled the discriminator.

## Adversarial Process:
In this case, zero-sum means that when the discriminator successfully identifies real and fake samples, it is rewarded or no change is needed to the model parameters, whereas the generator is penalized with large updates to model parameters.

Alternately, when the generator fools the discriminator, it is rewarded, or no change is needed to the model parameters, but the discriminator is penalized and its model parameters are updated.

At a limit, the generator generates perfect replicas from the input domain every time, and the discriminator cannot tell the difference and predicts “unsure” (e.g. 50% for real and fake) in every case. This is just an example of an idealized case; we do not need to get to this point to arrive at a useful generator model.


<p align="center">
<img src="https://github.com/ShihabYasin/shihabyasin.github.io/blob/gh-pages/public/img/29.png?raw=true?" alt="Illustration" width="280x" height="260px"/>
</p>

## Conditional GANs:

Generative adversarial nets can be extended to a conditional model if both the generator and discriminator are conditioned on some extra information y. y could be any kind of auxiliary information, such as class labels or data from other modalities. We can perform the conditioning by feeding y into the both the discriminator and generator as [an] additional input layer.


<p align="center">
<img src="https://github.com/ShihabYasin/shihabyasin.github.io/blob/gh-pages/public/img/30.png?raw=true?" alt="Illustration" width="420px" height="220px"/>
</p>


The discriminator is also conditioned, meaning that it is provided both with an input image that is either real or fake and the additional input. In the case of a classification label type conditional input, the discriminator would then expect that the input would be of that class, in turn teaching the generator to generate examples of that class in order to fool the discriminator.

In this way, a conditional GAN can be used to generate examples from a domain of a given type.

Taken one step further, the GAN models can be conditioned on an example from the domain, such as an image. This allows for applications of GANs such as text-to-image translation, or image-to-image translation. This allows for some of the more impressive applications of GANs, such as style transfer, photo colorization, transforming photos from summer to winter or day to night, and so on.

In the case of conditional GANs for image-to-image translation, such as transforming day to night, the discriminator is provided examples of real and generated nighttime photos as well as (conditioned on) real daytime photos as input. The generator is provided with a random vector from the latent space as well as (conditioned on) real daytime photos as input.


**Ref:** 
1. ["Generative Adversarial Networks" by Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio](https://arxiv.org/abs/1406.2661)
2. ["Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks" by  Alec Radford, Luke Metz, Soumith Chintala](https://arxiv.org/abs/1511.06434)
3. ["Conditional Generative Adversarial Nets by Mehdi Mirza, Simon Osindero](https://arxiv.org/abs/1411.1784)
4. ["NIPS 2016 Tutorial: Generative Adversarial Networks" by Ian Goodfellow](https://arxiv.org/abs/1701.00160)